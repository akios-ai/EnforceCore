<p align="center">
  <img src="https://raw.githubusercontent.com/akios-ai/EnforceCore/main/.github/assets/logo.svg" alt="EnforceCore" width="280" />
</p>

<h1 align="center">EnforceCore</h1>

<p align="center">
  <strong>The runtime enforcement layer for agentic AI systems.</strong><br />
  Policy-driven Â· Fail-closed Â· Tamper-proof audit trails
</p>

<p align="center">
  <a href="https://github.com/akios-ai/EnforceCore/actions"><img src="https://img.shields.io/github/actions/workflow/status/akios-ai/EnforceCore/ci.yml?branch=main&style=flat-square&label=CI" alt="CI" /></a>
  <img src="https://img.shields.io/badge/python-3.11%20%7C%203.12%20%7C%203.13-blue?style=flat-square" alt="Python" />
  <a href="LICENSE"><img src="https://img.shields.io/badge/license-Apache_2.0-blue?style=flat-square" alt="License" /></a>
  <img src="https://img.shields.io/badge/coverage-95%25-brightgreen?style=flat-square" alt="Coverage" />
  <img src="https://img.shields.io/badge/tests-1510_passed-brightgreen?style=flat-square" alt="Tests" />
</p>

<p align="center">
  <a href="#quick-start">Quick Start</a> Â·
  <a href="docs/architecture.md">Architecture</a> Â·
  <a href="docs/roadmap.md">Roadmap</a> Â·
  <a href="docs/api-design.md">API Reference</a> Â·
  <a href="docs/contributing.md">Contributing</a>
</p>

> **âš ï¸ Disclaimer:** EnforceCore is provided "as is", without warranty of any kind, express or
> implied. It is a technical enforcement tool â€” **not a compliance certification**. Using EnforceCore
> does not guarantee regulatory compliance with any standard or law.
> See [DISCLAIMER.md](DISCLAIMER.md) and [LICENSE](LICENSE) for full legal terms.

---

## The Problem

Most agent safety solutions operate at the **prompt level** â€” they *ask* the LLM to be safe. This is fundamentally broken: prompts can be bypassed, jailbroken, or ignored.

**EnforceCore operates at the runtime boundary** â€” the moment before a tool or API is actually called. At this layer, enforcement is **mandatory**, not advisory. If a call violates policy, it never executes. Period.

```python
from enforcecore import enforce

@enforce(policy="policies/strict.yaml")
async def search_web(query: str) -> str:
    """This call is policy-enforced before execution."""
    return await api.search(query)
```

## Why EnforceCore?

| | Prompt Guardrails | EnforceCore |
|---|---|---|
| **Layer** | Inside the LLM | Runtime call boundary |
| **Bypassable?** | Yes (jailbreaks, prompt injection) | No (code-level enforcement) |
| **Auditable?** | No | Yes (Merkle-chained trails) |
| **Property-tested?** | No | Yes ([22 Hypothesis properties](docs/formal/invariants.md)) |
| **EU AI Act aligned?** | âŒ | âœ… (see [disclaimer](#legal)) |

> **EnforceCore vs. OS-level security:** EnforceCore operates at the
> *application semantic layer* â€” it understands tool calls, PII, and cost
> budgets. It does not replace SELinux, AppArmor, seccomp, or container
> sandboxing. These are complementary â€” use both for
> [defense-in-depth](docs/defense-in-depth.md).

---

## Architecture

```
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚        Agent  (LangGraph Â· CrewAI Â· AutoGen Â· Python)         â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚  tool_call(args)
                                  â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   @enforce(policy=â€¦)    â”‚  â† decorator / adapter
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â–¼â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
  â•‘                           Enforcer                            â•‘
  â•‘                                                               â•‘
  â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â•‘
  â•‘  â”‚  Policy Engine  â”‚  â”‚    Redactor     â”‚  â”‚    Guard    â”‚  â•‘
  â•‘  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚  â•‘
  â•‘  â”‚  YAML rules     â”‚â”€â–¶â”‚  PII detect     â”‚â”€â–¶â”‚ time Â· mem  â”‚  â•‘
  â•‘  â”‚  allow / deny   â”‚  â”‚  & redact       â”‚  â”‚ cost Â· kill â”‚  â•‘
  â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â•‘
  â•‘                                                    â”‚          â•‘
  â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â” â•‘
  â•‘  â”‚                       Audit Trail                       â”‚ â•‘
  â•‘  â”‚          Merkle chain Â· tamper-proof Â· always logs      â”‚ â•‘
  â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                  â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â–¼                                     â–¼
       âœ…  allowed                             âŒ  blocked
        â†’ execute tool                      â†’ raise PolicyViolation
```

<table>
<tr><td><strong>Policy Engine</strong></td><td>Declarative YAML policies â€” allowed tools, denied tools, violation handling</td></tr>
<tr><td><strong>Enforcer</strong></td><td>Intercepts every call, evaluates policy, blocks or allows</td></tr>
<tr><td><strong>Redactor</strong></td><td>Real-time PII detection and redaction on inputs &amp; outputs</td></tr>
<tr><td><strong>Auditor</strong></td><td>Tamper-proof Merkle-tree audit trail for every enforced call</td></tr>
<tr><td><strong>Guard</strong></td><td>Resource limits (time, memory, cost) with hard kill switch</td></tr>
</table>

---

## Quick Start

### Install

```bash
pip install enforcecore
```

### 1. Define a Policy

```yaml
# policy.yaml
name: "my-agent-policy"
version: "1.0"

rules:
  allowed_tools:
    - "search_web"
    - "calculator"
    - "get_weather"
  denied_tools:
    - "execute_shell"
  max_output_size_bytes: 524288   # 512KB

on_violation: "block"
```

### 2. Protect Your Tools

```python
from enforcecore import enforce

# Decorator â€” sync or async, just works
@enforce(policy="policy.yaml")
async def search_web(query: str) -> str:
    return await api.search(query)

@enforce(policy="policy.yaml")
def calculator(expr: str) -> float:
    return eval(expr)  # policy controls whether this tool can be called
```

### 3. See It Work

```python
# âœ… Allowed â€” tool is in the allowed list
result = await search_web("latest AI papers")

# âŒ Blocked â€” tool not allowed, raises ToolDeniedError
@enforce(policy="policy.yaml")
async def execute_shell(cmd: str) -> str:
    return subprocess.run(cmd, capture_output=True).stdout
```

### 4. Programmatic Control

```python
from enforcecore import Enforcer, Policy

policy = Policy.from_file("policy.yaml")
enforcer = Enforcer(policy)

# Direct invocation (sync)
result = enforcer.enforce_sync(my_tool, arg1, arg2, tool_name="my_tool")

# Direct invocation (async)
result = await enforcer.enforce_async(my_tool, arg1, tool_name="my_tool")
```

> ğŸ“– See [examples/quickstart.py](examples/quickstart.py) for a complete runnable demo.

---

## Framework Integrations

EnforceCore works with **any** Python-based agent system â€” no lock-in:

| Framework | Status | Example |
|---|---|---|
| **Plain Python** | âœ… Available | `@enforce()` decorator |
| **LangGraph** | âœ… Available | `@enforced_tool(policy="...")` |
| **CrewAI** | âœ… Available | `@enforced_tool(policy="...")` |
| **AutoGen** | âœ… Available | `@enforced_tool(policy="...")` |

```python
# LangGraph â€” one-line enforcement
from enforcecore.integrations.langgraph import enforced_tool

@enforced_tool(policy="policy.yaml")
def search(query: str) -> str:
    """Search the web."""
    return web_search(query)

# CrewAI
from enforcecore.integrations.crewai import enforced_tool

@enforced_tool(policy="policy.yaml")
def calculator(expr: str) -> str:
    """Calculate."""
    return str(eval(expr))

# AutoGen
from enforcecore.integrations.autogen import enforced_tool

@enforced_tool(policy="policy.yaml", description="Search the web")
async def search(query: str) -> str:
    return await web_search(query)
```

> No hard dependencies on any framework â€” adapters use optional imports.

---

## Key Design Principles

- **ğŸ”’ Fail-closed** â€” if enforcement fails, the call is blocked. Never fails open.
- **âš¡ Async-native** â€” first-class support for both sync and async from day one.
- **ğŸŒ Cross-platform** â€” core works on Linux, macOS, and Windows. Advanced Linux hardening optional.
- **ğŸ“¦ Zero lock-in** â€” no hard dependency on any agent framework.
- **ğŸ“Š Honest benchmarks** â€” real overhead numbers, not marketing claims.

## Performance

> Measured with 1 000 iterations + 100 warmup on Apple Silicon (arm64), Python 3.13.
> Run `python -m benchmarks.run` for your hardware. See [docs/benchmarks.md](docs/benchmarks.md) for methodology.

| Component | P50 (ms) | P99 (ms) |
|---|---|---|
| Policy evaluation | 0.012 | 0.228 |
| PII redaction (short) | 0.028 | 0.275 |
| PII redaction (~2KB) | 0.129 | 0.220 |
| Audit entry (write) | 0.068 | 0.232 |
| Audit chain verify (100 entries) | 1.114 | 1.457 |
| Resource guard | < 0.001 | < 0.001 |
| Rate limiter | < 0.001 | 0.002 |
| Secret detection | 0.012 | 0.017 |
| **Full enforcement (E2E)** | **0.056** | **0.892** |
| **E2E + PII redaction** | **0.093** | **0.807** |

Negligible compared to tool call latency (100msâ€“10s for API calls).

---

## Roadmap

| Release | Focus | Status |
|---|---|---|
| **v1.0.0a1** | Core Enforcer + Policy Engine | âœ… Shipped |
| **v1.0.1a1** | PII Redactor | âœ… Shipped |
| **v1.0.2a1** | Merkle Audit Trail | âœ… Shipped |
| **v1.0.3a1** | Resource Guard + KillSwitch | âœ… Shipped |
| **v1.0.4a1** | Framework Integrations | âœ… Shipped |
| **v1.0.5a1** | Evaluation Suite | âœ… Shipped |
| **v1.0.6a1** | Hardening + Polish | âœ… Shipped |
| **v1.0.7a1** | Plugin & Extensibility | âœ… Shipped |
| **v1.0.8a1** | Deep Inspection & Network Control | âœ… Shipped |
| **v1.0.9a1** | CLI & Policy Tooling | âœ… Shipped |
| **v1.0.10a1** | Observability & Telemetry | âœ… Shipped |
| **v1.0.11a1** | Documentation & Academic Foundation | âœ… Shipped |
| **v1.0.12a1** | Threat Model & Compliance Mapping | âœ… Shipped |
| **v1.0.13a1** | Formal Verification & Property Testing | âœ… Shipped |
| **v1.0.14a1** | Reproducible Benchmarks & Evaluation | âœ… Shipped |
| **v1.0.15a1** | End-to-End Examples & Integration | âœ… Shipped |
| **v1.0.16a1** | API Freeze & Stability Audit | âœ… Shipped |
| **v1.0.17a1** | Adversarial Scenario Expansion | âœ… Shipped |
| **v1.0.18a1** | Security Landscape & Positioning | âœ… Shipped |
| **v1.0.19a1** | Pre-Release Polish & Community | âœ… Shipped |
| **v1.0.20a1** | Packaging & Publication | âœ… Shipped |
| **v1.0.21a1** | Security Fixes | âœ… Shipped |
| **v1.0.22a1** | Infrastructure Hardening | âœ… Shipped |
| **v1.0.23a1** | Release Infrastructure & CI Fix | âœ… Shipped |
| **v1.0.24a1** | Security Audit | âœ… Shipped |
| **v1.0.25a1** | API Pruning (110 â†’ 30 symbols) | âœ… Shipped |
| **v1.0.0b1** | First Beta (deprecation warnings) | âœ… Shipped |
| **v1.0.0b2** | Security Fix (from_dict hoisting) | âœ… Shipped |
| **v1.0.0b3** | Documentation Accuracy Fixes | âœ… Shipped |
| **v1.0.0b4** | Tamper-Evidence (append-only + witness) | âœ… Shipped |
| **v1.0.0b5** | Settings Integration + Docs + Edge-Case Tests | âœ… Shipped |
| **v1.0.0** | **Stable Release** | ğŸ¯ Target |

See [docs/roadmap.md](docs/roadmap.md) for detailed scope of each release.

---

## Documentation

| | |
|---|---|
| ğŸ“ [Architecture](docs/architecture.md) | Technical design and component overview |
| ğŸ—ºï¸ [Roadmap](docs/roadmap.md) | v1.0.x incremental release plan |
| ğŸ”§ [API Design](docs/api-design.md) | Public API surface and patterns |
| ğŸ“š [API Reference](https://akios.ai/enforcecore) | API documentation |
| ğŸ› ï¸ [Developer Guide](docs/dev-guide.md) | Setup, standards, and workflow |
| ğŸ§ª [Tech Stack](docs/tech-stack.md) | Technology choices and rationale |
| ğŸ“Š [Evaluation](docs/evaluation.md) | Adversarial scenarios, benchmarks, and reports |
| ğŸ“„ [Related Work](docs/related-work.md) | Survey and academic positioning |
| ğŸ›¡ï¸ [Defense-in-Depth](docs/defense-in-depth.md) | Security layer architecture and deployment stacks |
| ğŸ§­ [Tool Selection](docs/security/tool-selection.md) | When to use EnforceCore vs. OS-level security |
| â“ [FAQ](docs/faq.md) | Frequently asked questions |
| ğŸ” [Troubleshooting](docs/troubleshooting.md) | Common errors and debugging tips |
| ğŸŒ [Vision](docs/vision.md) | Why EnforceCore exists |
| ğŸ¤ [Contributing](CONTRIBUTING.md) | How to contribute |
| ğŸ“‹ [Code of Conduct](CODE_OF_CONDUCT.md) | Community standards |
| ğŸ”’ [Security](SECURITY.md) | Vulnerability reporting policy |

---

## For Researchers

EnforceCore applies established computer science principles â€” runtime
verification, reference monitors, information-flow control â€” to the novel
problem of AI agent safety. We welcome academic collaboration.

- ğŸ“„ [**Related Work**](docs/related-work.md) â€” survey of runtime verification
  for AI agents, positioning vs. NeMo Guardrails, LlamaGuard, and others
- ğŸ“‘ [**CITATION.cff**](CITATION.cff) â€” machine-readable citation metadata
  ([how to cite](#citation))
- ğŸ”¬ [**Open Research Questions**](docs/related-work.md#5-open-research-questions) â€”
  policy composition, temporal properties, adversarial robustness
- ğŸ§ª [**Evaluation Suite**](docs/evaluation.md) â€” reproducible adversarial
  benchmarks with 20 scenarios across 10 threat categories
- ğŸ“ [**Architecture**](docs/architecture.md) â€” formal design with Mermaid
  diagrams

### Citation

```bibtex
@software{enforcecore2026,
  title  = {EnforceCore: Runtime Enforcement Layer for Agentic AI Systems},
  author = {{AKIOUD AI}},
  year   = {2026},
  url    = {https://github.com/akios-ai/EnforceCore},
  license = {Apache-2.0}
}
```

---

## For Enterprises

EnforceCore is designed for production deployment in regulated environments.

| Concern | EnforceCore Feature |
|---|---|
| **Audit compliance** | Merkle-chained, tamper-evident audit trails with OS-enforced append-only and hash-only remote witnesses |
| **Data protection** | Real-time PII redaction (11 categories) |
| **Cost control** | Per-call and cumulative cost budgets |
| **Access governance** | Declarative tool allow/deny policies |
| **Network control** | Domain allowlisting with wildcard support |
| **Rate limiting** | Per-tool, per-window, global rate caps |
| **Incident response** | Structured violation events + webhook alerts |
| **EU AI Act** | Designed for Article 9, 13, 14, 15 alignment |

- ğŸ”’ **Fail-closed by default** â€” if enforcement fails, the call is blocked
- ğŸ“¦ **No vendor lock-in** â€” Apache 2.0, works with any agent framework
- ğŸŒ **Cross-platform** â€” Linux, macOS, Windows (advanced Linux hardening optional)
- ğŸ“Š **Observability** â€” OpenTelemetry traces, Prometheus-compatible metrics

---

## Development

```bash
# Clone
git clone https://github.com/akios-ai/EnforceCore.git
cd EnforceCore

# Setup
python -m venv .venv && source .venv/bin/activate
pip install -e ".[dev]"

# Test
pytest --cov=enforcecore

# Lint
ruff check . && ruff format --check .
```

**Current stats:** 1510 tests Â· 95% coverage Â· 0 lint errors

---

## Acknowledgements

EnforceCore builds on a foundation of prior work in computer science and AI safety:

- **Runtime Verification** â€” Leucker & Schallhart (2009), Havelund & Goldberg (2005)
- **Reference Monitors** â€” Anderson (1972) for the tamperproof, always-invoked enforcement model
- **Information Flow Control** â€” Sabelfeld & Myers (2003) for the PII boundary model
- **Audit Integrity** â€” Merkle (1987), Crosby & Wallach (2009) for hash-chained tamper evidence
- **Agent Containment** â€” Armstrong et al. (2012), Babcock et al. (2016) for the containment framing
- **Evaluation Methodology** â€” Prof. ValÃ©rie Viet Triem Tong (CentraleSupÃ©lec, IRISA/PIRAT) for feedback on adversarial evaluation strategies and containment testing
- **Microsoft Presidio** â€” for design inspiration on PII detection patterns
- **EU AI Act (2024)** â€” Articles 9, 13, 14, 15 directly shaped the design

See [CONTRIBUTORS.md](CONTRIBUTORS.md) and [docs/related-work.md](docs/related-work.md) for full citations.

---

## Legal

EnforceCore is provided **"as is"**, without warranty of any kind. See [DISCLAIMER.md](DISCLAIMER.md) for full legal terms.

EnforceCore is a **technical tool**, not a compliance certification. Using EnforceCore does not guarantee regulatory compliance. Always consult qualified legal counsel for compliance requirements.

## License

[Apache 2.0](LICENSE) â€” free for open-source and commercial use.

Copyright 2025â€“2026 AKIOUD AI, SAS. See [LICENSE](LICENSE) for details.

